{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "- Create a Convolutional Neural Network for classifying nuts and bots\n",
    "- To learn the use of commonly used deep learning layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,\\\n",
    "Conv2D, MaxPooling2D\n",
    "import skimage\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/nuts_n_bolts_master/all_dl/train'\n",
    "test_path = '../data/nuts_n_bolts_master/all_dl/test'\n",
    "val_path = '../data/nuts_n_bolts_master/all_dl/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 50x65\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 50x65\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a simple CNN model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a model in keras for nuts_and_bolts classfication\n",
    "# The model consists of two convolutional layers\n",
    "# Declare a sequential model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare 2 layers each containing 32 kernel of 3 *3 convolutional filters for the model with input shape = (50,65,3) and activation layer in each layer is relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare rest of the network for the model\n",
    "- Add a maxpooling layer with pool_size - (2,2)\n",
    "- Then flatten the model\n",
    "- Add two fully connected layer, the first one had 128 neurons with relu activation and the second one has w neurons with softmax activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "print(train_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the mode with cross_entropy loss and adam optimiser and with the metrics to be accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 5s - loss: 0.6602 - acc: 0.7553 - val_loss: 0.4174 - val_acc: 0.8684\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 4s - loss: 0.4921 - acc: 0.7691 - val_loss: 0.3985 - val_acc: 0.8421\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 3s - loss: 0.3238 - acc: 0.8355 - val_loss: 0.2182 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 4s - loss: 0.2617 - acc: 0.8722 - val_loss: 0.2669 - val_acc: 0.8421\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 4s - loss: 0.1893 - acc: 0.9267 - val_loss: 0.1183 - val_acc: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121a49a90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Test score: 0.6622934804256635\n",
      "Test accuracy: 0.7991543327779145\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's increase the number of convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets test results for our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30/30 [==============================] - 11s - loss: 0.1453 - acc: 0.9463 - val_loss: 0.2006 - val_acc: 0.9211\n",
      "Epoch 2/5\n",
      "30/30 [==============================] - 10s - loss: 0.1242 - acc: 0.9678 - val_loss: 0.3255 - val_acc: 0.8421\n",
      "Epoch 3/5\n",
      "30/30 [==============================] - 10s - loss: 0.2103 - acc: 0.9153 - val_loss: 0.0588 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "30/30 [==============================] - 10s - loss: 0.1103 - acc: 0.9475 - val_loss: 0.1283 - val_acc: 0.9474\n",
      "Epoch 5/5\n",
      "30/30 [==============================] - 11s - loss: 0.1010 - acc: 0.9611 - val_loss: 0.1051 - val_acc: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1314723c8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=300 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.7832948058552205\n",
      "Test accuracy: 0.830866805720783\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets analyse the effect of adding a few drop out layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model to analyse if dropout increases accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30/30 [==============================] - 11s - loss: 0.3579 - acc: 0.8657 - val_loss: 0.1882 - val_acc: 0.9474\n",
      "Epoch 2/5\n",
      "30/30 [==============================] - 10s - loss: 0.2520 - acc: 0.9060 - val_loss: 0.1718 - val_acc: 0.8947\n",
      "Epoch 3/5\n",
      "30/30 [==============================] - 10s - loss: 0.2516 - acc: 0.8898 - val_loss: 0.1638 - val_acc: 0.9167\n",
      "Epoch 4/5\n",
      "30/30 [==============================] - 11s - loss: 0.1453 - acc: 0.9517 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "30/30 [==============================] - 11s - loss: 0.1182 - acc: 0.9530 - val_loss: 0.1416 - val_acc: 0.8947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133885358>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=300 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.6438897287760552\n",
      "Test accuracy: 0.8224101459753186\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try out different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = ['relu','tanh','sigmoid']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function to construct and evaluate a model to make the comparison of different loss functions easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_evaluate_model(actv):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation= actv))\n",
    "    model.add(Dense(2, activation= actv))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=2,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)\n",
    "    score = model.evaluate_generator(test_generator, steps=50)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVATION relu \n",
      "\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 4s - loss: 2.2698 - acc: 0.5094 - val_loss: 0.6931 - val_acc: 0.5526\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 3s - loss: 0.6931 - acc: 0.5585 - val_loss: 0.6931 - val_acc: 0.5278\n",
      "Test score: 0.6931471824645996\n",
      "Test accuracy: 0.5504201767700059\n",
      "11.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "\n",
      "\n",
      "ACTIVATION tanh \n",
      "\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 4s - loss: 2.9525 - acc: 0.4903 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 3s - loss: 0.6931 - acc: 0.5598 - val_loss: 0.6931 - val_acc: 0.5263\n",
      "Test score: 0.6931471824645996\n",
      "Test accuracy: 0.5462184951585882\n",
      "11.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "\n",
      "\n",
      "ACTIVATION sigmoid \n",
      "\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 4s - loss: 1.2244 - acc: 0.5626 - val_loss: 1.3256 - val_acc: 0.5263\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 3s - loss: 1.3646 - acc: 0.4712 - val_loss: 1.1337 - val_acc: 0.5263\n",
      "Test score: 1.0906576566836412\n",
      "Test accuracy: 0.5462184972560206\n",
      "11.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for actv in activations:\n",
    "    print('ACTIVATION',actv,'\\n')\n",
    "    %timeit -n1 -r1 build_and_evaluate_model(actv)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
